# IRLAlignment
## Get started

Install the dependencies

```
pip install -r requirements.txt
pip install poetry
```

## Step 0: Generate Demonstration

Demonstration is generated by a well-trained policy model vwxyzjn/EleutherAI_pythia-6.9b-deduped__
reward__tldr(https://huggingface.co/vwxyzjn/EleutherAI_pythia-6.9b-deduped__reward__tldr/tree/reward__44413__1706651113)

```
./bash/sft_data_generation.sh 
```
After running this, our demonstration is generated in /generated_data folder.
Currently, we use a 2.8B model to generate demonstrations on an A40 GPU to prevent OOM issues. You can configure the model for demonstration generation in sft_data_generation.bash.

## Step 1: IRL Training

Then we run
```
./bash/IRL_Pipeline.sh
```
Our IRL pipeline includes four steps:
### Step 1.1: SFT.
### Step 1.2: Generate Demonstration-agent pairs for reward update.
### Step 1.3: Reward Update.
### Step 1.4: Using PPO to update policy and go back to step 1.2.

Details are in the bash.
